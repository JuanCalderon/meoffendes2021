{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5060, 1),\n",
       " (5060, 1),\n",
       "                                                texto\n",
       " 0  Soy el Clint Eastwood de los Puentes de Madiso...\n",
       " 1  Actualmente ya pas√≥ de moda la pucha joto, aho...\n",
       " 2  ¬øEs cierto esto? Y no me refiero a lo que dijo...\n",
       " 3  Vuela pega y esquiva... la neta est√° de la ver...\n",
       " 4  Mejor puto disfraz de la noche!!!! üëäüëäüëäPor terc...,\n",
       "    clase\n",
       " 0      0\n",
       " 1      1\n",
       " 2      0\n",
       " 3      0\n",
       " 4      0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# cargar DataSet con los tweets de entrenamiento\n",
    "train_mx = pd.read_csv('mx-train-data-non-contextual.csv', names=['texto'],  header=0)# , nrows=30, header=1) \n",
    "# cargar las clases de cada tweet de entrenamiento\n",
    "sol = pd.read_csv('mx-train-outputs.sol', names=[\"clase\"])\n",
    "\n",
    "train_mx.shape, sol.shape, train_mx.head(5), sol.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4048, 1),\n",
       " (4048, 2),\n",
       "                                                   texto  clase\n",
       " 311   En estos momentos de la vida es d√≥nde me pregu...      0\n",
       " 2863  @USUARIO Que andas de payasa jaja queriendote ...      0\n",
       " 2300  Los subt√≠tulos en espa√±ol de The Fosters est√°n...      0\n",
       " 2346  Pague infracciones del bmw... y lo lleve a ver...      0\n",
       " 396   Vergaa neta me caga que todos los pinches a√±os...      0,\n",
       "                                                texto  clase\n",
       " 1  Actualmente ya pas√≥ de moda la pucha joto, aho...      1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.model_selection as model_selection\n",
    "\n",
    "# split del datataset completo en entrenamiento | test\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(train_mx, sol, train_size=0.8, random_state=True)\n",
    "\n",
    "# Juntar texto|clase y re-ordenar aleatoriamente \n",
    "X_y_train_shuffled = X_train.join(y_train).sample(frac=1)\n",
    "\n",
    "X_train.shape, X_y_train_shuffled.shape, X_y_train_shuffled.head(5), X_y_train_shuffled.loc[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254     @USUARIO @USUARIO @USUARIO Despu√©s de todo hay ratas de alcantarilla de 4 patas menos feas que estas RATAS de dos patas. ASQUEROSOS\n",
      "Name: texto, dtype: object\n",
      "     clase\n",
      "254  1    \n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_colwidth', -1):\n",
    "    print(X_y_train_shuffled.loc[[254]]['texto'])\n",
    "    print(sol.loc[[254]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5504, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aumentado de X_train / y_train con bi-frases\n",
    "_ = X_y_train_shuffled.iloc[0]\n",
    "train_bi_frase = pd.DataFrame([_], columns = ['texto', 'clase'])\n",
    "train_bi_frase\n",
    "\n",
    "for index, row in X_y_train_shuffled.iloc[1:].iterrows():\n",
    "    try:\n",
    "        train_bi_frase =  train_bi_frase.append(row)\n",
    "        if _['clase'] == row['clase']:\n",
    "            bi_frase = {'texto': _['texto'] + row['texto'], 'clase':row['clase']}\n",
    "            train_bi_frase = train_bi_frase.append(bi_frase, ignore_index=True)\n",
    "            _ =  {'texto': '_VACIA_', 'clase': None}\n",
    "        else:   \n",
    "            _ = row\n",
    "    except Exception as exc:\n",
    "        print(exc)\n",
    "        _ = row\n",
    "        continue\n",
    "        \n",
    "train_bi_frase.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               texto  clase\n",
      "0  En estos momentos de la vida es d√≥nde me pregu...      0\n",
      "1  @USUARIO Que andas de payasa jaja queriendote ...      0\n",
      "2  En estos momentos de la vida es d√≥nde me pregu...      0\n",
      "3  Los subt√≠tulos en espa√±ol de The Fosters est√°n...      0\n",
      "4  Pague infracciones del bmw... y lo lleve a ver...      0\n",
      "                                                texto  clase\n",
      "7   pues si soy joto, me vale verga Jajajaja creo ...      1\n",
      "9   Si te vas a ir a la verga de mi lado d√©jame ig...      1\n",
      "13  chinguen su madre putos chilenos de mierda, #M...      1\n",
      "14  Cuando vas a ver una pelicula todos esperan si...      1\n",
      "15  chinguen su madre putos chilenos de mierda, #M...      1\n"
     ]
    }
   ],
   "source": [
    "# solo para checar algunas bi-frases\n",
    "print(train_bi_frase.loc[(train_bi_frase['clase'] == 0)].head(5))\n",
    "print(train_bi_frase.loc[(train_bi_frase['clase'] == 1)].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12    El fruto del servicio es la paz, Madre Teresa de Calcuta.Primera vez que me dan asueto el d√≠a de muertos y yo de viaje de trabajo no mamar\n",
      "Name: texto, dtype: object\n",
      "19    Dicen que el que madura se arruga... Pues yo ya me ando poniendo bien madurito de los p√°rpados.\n",
      "Name: texto, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# ver una bifrase completa por √≠ndice\n",
    "with pd.option_context('display.max_colwidth', -1):\n",
    "    print(train_bi_frase.loc[[12]]['texto'])\n",
    "    print(train_bi_frase.loc[[19]]['texto'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5504,),\n",
       " (5504,),\n",
       " 0    En estos momentos de la vida es d√≥nde me pregu...\n",
       " 1    @USUARIO Que andas de payasa jaja queriendote ...\n",
       " 2    En estos momentos de la vida es d√≥nde me pregu...\n",
       " 3    Los subt√≠tulos en espa√±ol de The Fosters est√°n...\n",
       " 4    Pague infracciones del bmw... y lo lleve a ver...\n",
       " Name: texto, dtype: object,\n",
       " 0    0\n",
       " 1    0\n",
       " 2    0\n",
       " 3    0\n",
       " 4    0\n",
       " Name: clase, dtype: int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re-split del train_bi_frase\n",
    "\n",
    "X_train = train_bi_frase['texto']\n",
    "y_train = train_bi_frase['clase']\n",
    "\n",
    "X_train = X_train.squeeze() \n",
    "X_test = X_test.squeeze() \n",
    "y_train = y_train.squeeze() \n",
    "y_test = y_test.squeeze()\n",
    "\n",
    "X_train.shape, y_train.shape, X_train.head(), y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelos para EvomSA\n",
    "\n",
    "from EvoMSA.utils import download\n",
    "from EvoMSA.base import EvoMSA\n",
    "\n",
    "from EvoMSA.model import TextModelInv\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "haha = download('haha2018_Es.evomsa')\n",
    "mexa3t = download('mexa3t2018_aggress_Es.evomsa')\n",
    "misoginia = download('misoginia_Es.evomsa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Calderas\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:315: UserWarning: Trying to unpickle estimator LinearSVC from version 0.22.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\Calderas\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:315: UserWarning: Trying to unpickle estimator GaussianNB from version 0.22.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:58<01:58, 29.54s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:14<00:28, 14.40s/it]\u001b[A\n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:27<00:13, 13.69s/it]\u001b[A\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:33<00:00, 11.24s/it]\u001b[A\n",
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 62.67it/s]\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [01:32<01:34, 31.49s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:17<00:00, 17.42s/it]\u001b[A\n",
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 62.53it/s]\n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [01:50<00:51, 25.95s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|‚ñà‚ñà‚ñå       | 1/4 [00:16<00:49, 16.50s/it]\u001b[A\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:26<00:25, 12.82s/it]\u001b[A\n",
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:32<00:09,  9.77s/it]\u001b[A\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:36<00:00,  9.23s/it]\u001b[A\n",
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 102.84it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [02:30<00:00, 25.08s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:02<00:00,  1.74it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:03<00:00,  1.55it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 75.96it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 78.33it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 78.32it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 109.09it/s]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172.6022012233734 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:16<00:31,  7.95s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:04<00:08,  4.48s/it]\u001b[A\n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:08<00:04,  4.14s/it]\u001b[A\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:09<00:00,  3.23s/it]\u001b[A\n",
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 334.00it/s]\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:25<00:26,  8.76s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.17s/it]\u001b[A\n",
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 334.26it/s]\n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:31<00:14,  7.35s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|‚ñà‚ñà‚ñå       | 1/4 [00:06<00:18,  6.07s/it]\u001b[A\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:07<00:07,  3.56s/it]\u001b[A\n",
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:09<00:02,  2.56s/it]\u001b[A\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:09<00:00,  2.49s/it]\u001b[A\n",
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 333.84it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:41<00:00,  6.97s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 375.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Clasificador con Modelos\n",
    "# \"text_model_inv.TextModelInv\"\n",
    "# [TextModelInv,\"sklearn.svm.LinearSVC\"],\n",
    "evo = EvoMSA(TR=True, B4MSA=False, lang='es', Aggress=True,\n",
    "                 stacked_method='sklearn.naive_bayes.GaussianNB',\n",
    "                 models=[\n",
    "                     [TextModelInv,\"sklearn.svm.LinearSVC\"],\n",
    "                     [misoginia, \"sklearn.svm.LinearSVC\"],\n",
    "                     [haha, \"sklearn.svm.LinearSVC\"] ,\n",
    "                     [mexa3t, \"sklearn.svm.LinearSVC\"]\n",
    "                 ])\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "# Entrenamiento X_train | y_train\n",
    "evo.fit(X_train, y_train)    \n",
    "print(time.time() - start, \"seconds\")\n",
    "\n",
    "# Predicci√≥n con X_test\n",
    "pred = evo.predict(X_test)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       f1 score macro: 0.7471953201985903\n",
      "precision score macro: 0.7415315703840197\n",
      "   recall score macro: 0.7540005669080321\n",
      "       f1 score micro: 0.8033596837944664\n",
      "precision score micro: 0.8033596837944664\n",
      "   recall score micro: 0.8033596837944664\n"
     ]
    }
   ],
   "source": [
    "## \n",
    "print(\"       f1 score macro:\", metrics.f1_score(y_test, pred, average=\"macro\"))\n",
    "print(\"precision score macro:\", metrics.precision_score(y_test, pred, average=\"macro\"))\n",
    "print(\"   recall score macro:\", metrics.recall_score(y_test, pred, average=\"macro\"))  \n",
    "print(\"       f1 score micro:\", metrics.f1_score(y_test, pred, average=\"micro\"))\n",
    "print(\"precision score micro:\", metrics.precision_score(y_test, pred, average=\"micro\"))\n",
    "print(\"   recall score micro:\", metrics.recall_score(y_test, pred, average=\"micro\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
